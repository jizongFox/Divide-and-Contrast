#!/bin/bash
set -e
lr=0.0002
max_epoch=3
export PYTHONOPTIMIZE=1
export OPM_NUM_THREADS=1
save_dir=0601
batch_size=128

python train.py --enable_grad_4_extractor --save_dir=${save_dir}/baseline --max_epoch=${max_epoch} --lr=${lr} --batch_size=${batch_size}
python pretrain.py --save_dir ${save_dir}/pretrained_moclr --max_epoch=${max_epoch}   --lr=${lr} --batch_size=${batch_size}
python pretrain.py --save_dir ${save_dir}/pretrained_simclr --max_epoch=${max_epoch}   --lr=${lr} --batch_size=${batch_size}

python train.py --pretrained_checkpoint=${save_dir}/pretrained_moclr/pretrain.pth --save_dir=${save_dir}/finetune_moclr --max_epoch=${max_epoch}   --lr=${lr} --batch_size=${batch_size}
python train.py --pretrained_checkpoint=${save_dir}/pretrained_simclr/pretrain.pth --save_dir=${save_dir}/finetune_simclr --max_epoch=${max_epoch}   --lr=${lr} --batch_size=${batch_size}
