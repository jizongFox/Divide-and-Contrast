#!/bin/bash
set -e
lr=0.00000005
max_epoch=100
num_batches=500
python pretrain.py --save_dir pretrained_moclr --max_epoch=${max_epoch} --num_batches=${num_batches} --lr=${lr}

python train.py --pretrained_checkpoint=pretrained_moclr/pretrain.pth --save_dir=finetune --max_epoch=${max_epoch} --num_batches=${num_batches} --lr=${lr}

python train.py --enable_grad_4_extractor --save_dir=baseline --max_epoch=${max_epoch} --num_batches=${num_batches} --lr=${lr}
